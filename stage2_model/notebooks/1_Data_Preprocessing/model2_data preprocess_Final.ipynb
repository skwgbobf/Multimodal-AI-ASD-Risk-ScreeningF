{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASD Classification Project: Data Processing and Preparation\n",
    "\n",
    "This repository contains the code and documentation for a machine learning project focused on classifying individuals with Autism Spectrum Disorder (ASD) based on their behavioral responses and Social Responsiveness Scale (SRS) scores.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "The goal of this project is to develop a machine learning model that can accurately classify individuals into different groups (e.g., ASD, High-functioning, Typically Developing) based on their performance in a series of interactive tasks and their SRS scores.\n",
    "\n",
    "This README provides a detailed explanation of the data processing and preparation steps performed before training the classification model.\n",
    "\n",
    "## Data Description\n",
    "\n",
    "The project utilizes two main datasets:\n",
    "\n",
    "1.  **SRS Data (`SRS_data_total_1004_all_Oct232024_Nov01F.csv`):** This dataset contains Social Responsiveness Scale (SRS) scores for each individual. It includes the following columns (at a minimum):\n",
    "    -   `SubjectId`: Unique identifier for each individual.\n",
    "    -   `class`: The individual's classification (e.g., `asd`, `high`, `td`).\n",
    "    -   `combined`:  (Description of this column - add more context if you have it).\n",
    "\n",
    "2.  **Interaction Data (`text_exc_merged_df_F_1004_Oct18F.csv`):** This dataset contains information about each individual's interactions during the tasks, likely derived from speech-to-text analysis. The original columns included:\n",
    "    -   `SubjectId`: Unique identifier for each individual.\n",
    "    -   `Class_txt`: Text-based classification.\n",
    "    -   `Visit`: Visit number.\n",
    "    -   Columns ending with `_txt`: Textual descriptions of responses to specific tasks (e.g., `Responded to name_txt`, `Mimicked actions1_txt1`, etc.).\n",
    "    -   Columns without `_txt`: Likely indicate 'Y'/'N' (Yes/No) responses to tasks (e.g., `Responded to name`, `Mimicked actions1`, etc.).\n",
    "    -   `Class_ex`: Another classification column.\n",
    "\n",
    "## Data Processing and Preparation Steps\n",
    "\n",
    "The following steps were performed to prepare the data for the machine learning model:\n",
    "\n",
    "### 1. Import Libraries\n",
    "\n",
    "```python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "# Save the final result\n",
    "#1004\n",
    "# SRS_df = pd.read_csv('/home/skbae/Documents/skbae/ASD/paper/4.Multimodal_RiskST/Git/data/SRS_data_total_1004_all_Oct232024_Nov01F.csv')\n",
    "# SRS_df2.to_csv('./SRS_data_total_20250102_all_mapped_F.csv', header=True, index=False)\n",
    "# SRS_df = pd.read_csv('/home/skbae/Documents/skbae/ASD/paper/4.Multimodal_RiskST/Process/SRS_data_total_20250102_all_mapped_F.csv')\n",
    "SRS_df = pd.read_csv('/home/skbae/Documents/skbae/ASD/paper/4.Multimodal_RiskST/Process/SRS_data_total_1004_all_nov13F.csv')\n",
    "# from server :/home/skbae/ASD/speech/text_exc_merged_df_F_1004_Oct18F.csv\n",
    "df_interation = pd.read_csv('/home/skbae/Documents/skbae/ASD/paper/4.Multimodal_RiskST/Git/data/text_exc_merged_df_F_1004_Oct18F.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Columns\n",
    "\n",
    "df_interation.columns = ['SubjectId', 'Class_txt', 'Visit', 'Responded to name_txt','Mimicked actions1_txt1', 'Mimicked actions2_txt2','Played catch_txt', 'Fed baby doll_txt', 'Reacted to snack_txt','na_columns_name','Responded to name','Mimicked actions1','Mimicked actions2', 'Played catch', 'Fed baby doll', 'Reacted to snack','Class_ex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create \"Success/Failure\" Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check =['Responded to name', 'Mimicked actions1','Mimicked actions2','Played catch', 'Fed baby doll', 'Reacted to snack']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    df_interation[column + '_new2'] = df_interation[column].apply(lambda x: 'Success of ' + column if x == 'Y' else ('Failure of ' if x == 'N' else ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interation['Mimicked actions1'] = df_interation['Mimicked actions1'].replace('None', np.nan)\n",
    "df_interation['Mimicked actions2'] = df_interation['Mimicked actions2'].replace('None', np.nan)\n",
    "\n",
    "def combine_text_columns(row):\n",
    "   texts = [row['Mimicked actions1_txt1'], row['Mimicked actions2_txt2']]\n",
    "   filtered_texts = [str(text) for text in texts if pd.notna(text)]\n",
    "   return \", \".join(filtered_texts)\n",
    "\n",
    "df_interation['Mimicked actions_tot_txt'] = df_interation.apply(combine_text_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Mimicked Actions (Y/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interation[['Mimicked actions1', 'Mimicked actions2']] = df_interation[['Mimicked actions1', 'Mimicked actions2']].replace('-', np.nan)\n",
    "\n",
    "def combine_actions(row):\n",
    "    if pd.isna(row['Mimicked actions1']) and pd.isna(row['Mimicked actions2']):\n",
    "        return np.nan  # Return NaN if both are NaN\n",
    "    elif (row['Mimicked actions1'] == 'Y') or (row['Mimicked actions2'] == 'Y'):\n",
    "        return 'Y'\n",
    "    elif (row['Mimicked actions1'] == 'N') or (row['Mimicked actions2'] == 'N'):\n",
    "        return 'N'\n",
    "    else:\n",
    "        return '-'\n",
    "\n",
    "df_interation['Mimicked actions_tot'] = df_interation.apply(combine_actions, axis=1)\n",
    "columns_to_check =['Mimicked actions_tot']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    df_interation[column + '_new'] = df_interation[column].apply(lambda x: 'Success of ' + column if x == 'Y' else ('Failure of ' + column if x == 'N' else ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select and Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interation2=  df_interation[['SubjectId','Class_ex','Responded to name_new2', 'Mimicked actions1_new2', 'Mimicked actions2_new2','Played catch_new2','Fed baby doll_new2', 'Reacted to snack_new2']]\n",
    "merged_int_SRS_df = df_interation2.merge(SRS_df[['SubjectId', 'class', 'combined']], on='SubjectId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_int_SRS_df['class'] = merged_int_SRS_df['class'].replace({'asd': 'ASD', 'high': 'High', 'td': 'TD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to JSON and Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_int_SRS_df.to_json('./merged_int_SRS_df_op1_2nd_1004_Nov04F2.json', orient='records', lines=True)\n",
    "json_file_path = './merged_int_SRS_df_op1_2nd_1004_Nov04F2.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "json_file_path = './merged_int_SRS_df_op1_2nd_1004_Nov04F2.json'\n",
    "merged_int_SRS_df = pd.read_json(json_file_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'TD': 0, 'High': 1, 'ASD': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function_2(row):\n",
    "    task_results = f\" {row['Responded to name_new2']} ,{row['Mimicked actions1_new2'] + row['Mimicked actions2_new2']} ,{row['Played catch_new2']} ,{row['Fed baby doll_new2']} ,{row['Reacted to snack_new2']}\"\n",
    "    input_text = f\"Task Results: {task_results} Combined: {row['combined']}\"\n",
    "    label = label_mapping[row['Class_ex']]\n",
    "    return {\"SubjectId\": row['SubjectId'], \"text\": input_text, \"label\": label}\n",
    "\n",
    "preprocessed_2 = merged_int_SRS_df.apply(preprocess_function_2, axis=1)\n",
    "preprocessed_df2 = pd.DataFrame(preprocessed_2.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preprocessed_df2[['SubjectId','text', 'label']].head())\n",
    "df_sF= preprocessed_df2[['SubjectId','text', 'label']]\n",
    "df_sF.columns=['SubjectId','text','Class']\n",
    "df_sF['label'] = df_sF['Class']\n",
    "df_sF.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_mapping2 = {\n",
    "    # 0: 0, # TD\n",
    "    1: 0, # High risk of ASD\n",
    "    2: 1, # ASD\n",
    "}\n",
    "\n",
    "# Select only rows with 'High' and 'ASD'\n",
    "df_sF2 = df_sF[df_sF['Class'].isin([1, 2])]\n",
    "# df_sF2 = df_sF\n",
    "\n",
    "df_sF2['label'] = df_sF2['Class'].replace(ASD_mapping2)\n",
    "df_sF2.label.value_counts()\n",
    "df_m2=df_sF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    353\n",
       "0    162\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m2.to_json('./df_m2_5tasks_SRS_1004_Jan07F2.json', orient='records', lines=True)\n",
    "# df_m2.to_json('./df_m2_5tasks_SRS_20250102_Jan07F.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    print(\"GPU is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    # torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "random_seed = 42\n",
    "set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution in Train set:\n",
      "label\n",
      "1    0.686893\n",
      "0    0.313107\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Label distribution in Validation set:\n",
      "label\n",
      "1    0.634615\n",
      "0    0.365385\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Label distribution in Test set:\n",
      "label\n",
      "1    0.72549\n",
      "0    0.27451\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# Initialize StratifiedGroupKFold\n",
    "sgkf = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "# Get the indices for training and test sets\n",
    "train_idx, temp_idx = next(sgkf.split(df_m2, df_m2['label'], groups=df_m2['SubjectId']))\n",
    "\n",
    "# Create the training and test sets\n",
    "train = df_m2.iloc[train_idx]\n",
    "temp = df_m2.iloc[temp_idx]\n",
    "\n",
    "# Repeat for the validation set\n",
    "sgkf = StratifiedGroupKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "# Get the indices for validation and test sets\n",
    "for val_idx, test_idx in sgkf.split(temp, temp['label'], groups=temp['SubjectId']):\n",
    "    break\n",
    "\n",
    "# Create the validation and test sets\n",
    "val = temp.iloc[val_idx]\n",
    "test = temp.iloc[test_idx]\n",
    "\n",
    "# Verify the label distribution\n",
    "print(\"\\nLabel distribution in Train set:\")\n",
    "print(train['label'].value_counts(normalize=True))\n",
    "print(\"\\nLabel distribution in Validation set:\")\n",
    "print(val['label'].value_counts(normalize=True))\n",
    "print(\"\\nLabel distribution in Test set:\")\n",
    "print(test['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    283\n",
      "0    129\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    33\n",
      "0    19\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    37\n",
      "0    14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# after the chekin g the other lab part 2 below \n",
    "print(train['label'].value_counts())\n",
    "print(val['label'].value_counts())\n",
    "print(test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.to_json('./train_5tasks_SRS_1004_Jan07F2.son', orient='records', lines=True)\n",
    "val.to_json('./val_5tasks_SRS_1004_Jan07F2.json', orient='records', lines=True)\n",
    "test.to_json('./test_5tasks_SRS_1004_Jan07F2.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train.to_json('./train_5tasks_SRS_20250102_Jan07F.son', orient='records', lines=True)\n",
    "# val.to_json('./val_5tasks_SRS_20250102_Jan07F.json', orient='records', lines=True)\n",
    "# test.to_json('./test_5tasks_SRS_20250102_Jan07F.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
