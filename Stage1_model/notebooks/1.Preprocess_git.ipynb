{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "# high_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_HIGH_20241004).json\"\n",
    "# asd_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_20241004).json\"\n",
    "# td_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(NORMAL_20241004).json\"\n",
    "\n",
    "#20250102\n",
    "high_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/20250102/Survey/T_SurveySatus(ASD_HIGH).json\"\n",
    "asd_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/20250102/Survey/T_SurveySatus(ASD).json\"\n",
    "td_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/20250102/Survey/T_SurveySatus(NORMAL).json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Set the GPU to use\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def load_and_process_json_file(filepath, class_label):\n",
    "    \"\"\"\n",
    "    Loads a JSON file, adds a class label to each item, and returns the data.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "        if isinstance(json_data, list):\n",
    "            for item in json_data:\n",
    "                item['class'] = class_label\n",
    "        else:\n",
    "            json_data['class'] = class_label\n",
    "        return json_data\n",
    "\n",
    "def extract_survey_data(filepath, class_label):\n",
    "    \"\"\"\n",
    "    Extracts survey data from a JSON file and returns a list of dictionaries.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        data_json = json.load(file)\n",
    "\n",
    "    survey_data = []\n",
    "    for entry in data_json:\n",
    "        subject_id = entry['ParticipantInfo']['SubjectId']\n",
    "        gender = entry['ParticipantInfo']['Gender']\n",
    "        subject_group = entry['ParticipantInfo']['SubjectGroup']\n",
    "\n",
    "        # Extract eligibility criteria based on class_label\n",
    "        if class_label == \"High\":\n",
    "            eligibility_1_3 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASDHIGH_1_3\"), 'N/A')\n",
    "            eligibility_1_4 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASDHIGH_1_4\"), 'N/A')\n",
    "            eligibility_1_5 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASDHIGH_1_5\"), 'N/A')\n",
    "            eligibility_1_2 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASDHIGH_1_2\"), 'N/A')\n",
    "            eligibility_2_2 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASDHIGH_2_2\"), 'N/A')\n",
    "            eligibility_2_3 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASDHIGH_2_3\"), 'N/A')\n",
    "            eligibility_2_4 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASDHIGH_2_4\"), 'N/A')\n",
    "\n",
    "            survey_data.append({\n",
    "                \"Subject_Id\": subject_id,\n",
    "                \"Gender\": gender,\n",
    "                \"Class/ASD\": subject_group,\n",
    "                \"Family_History\": eligibility_1_3,\n",
    "                \"Premature_Infant\": eligibility_1_4,\n",
    "                \"Lanuage_Delay\": eligibility_1_5,\n",
    "                \"1st_Screening_ASD_Criteria\": eligibility_1_2,\n",
    "                \"Congenital_Genetic_Disorder\": eligibility_2_2,\n",
    "                \"History_of_Brain_Damage\": eligibility_2_3,\n",
    "                \"Seizure_or_Neurological_disease\": eligibility_2_4,\n",
    "            })\n",
    "\n",
    "        elif class_label == \"TD\":\n",
    "            eligibility_1_6 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_NORMAL_1_6\"), 'N/A')\n",
    "            eligibility_1_2 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_NORMAL_1_2\"), 'N/A')\n",
    "            eligibility_2_2 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_NORMAL_2_2\"), 'N/A')\n",
    "            eligibility_2_3 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_NORMAL_2_3\"), 'N/A')\n",
    "            eligibility_2_4 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_NORMAL_2_4\"), 'N/A')\n",
    "\n",
    "            survey_data.append({\n",
    "                \"Subject_Id\": subject_id,\n",
    "                \"Gender\": gender,\n",
    "                \"Class/ASD\": subject_group,\n",
    "                \"Family_History\": eligibility_1_6,\n",
    "                \"1st_Screening_ASD_Criteria\": eligibility_1_2,\n",
    "                \"Congenital_Genetic_Disorder\": eligibility_2_2,\n",
    "                \"History_of_Brain_Damage\": eligibility_2_3,\n",
    "                \"Seizure_or_Neurological_disease\": eligibility_2_4,\n",
    "            })\n",
    "\n",
    "        elif class_label == \"ASD\":\n",
    "            eligibility_1_3 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASD_1_3\"), 'N/A')\n",
    "            eligibility_1_2 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASD_1_2\"), 'N/A')\n",
    "            eligibility_1_4 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASD_1_4\"), 'N/A')\n",
    "            eligibility_1_5 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASD_1_5\"), 'N/A')\n",
    "            eligibility_1_6 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASD_1_6\"), 'N/A')\n",
    "            eligibility_2_2 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASD_2_2\"), 'N/A')\n",
    "            eligibility_2_3 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASD_2_3\"), 'N/A')\n",
    "            eligibility_2_4 = next((item['AnswerValue'] for item in entry['DemographicData']['SelectionCriteria'] if item['QuestionSeq'] == \"ELIGIBILITY_ASD_2_4\"), 'N/A')\n",
    "\n",
    "            survey_data.append({\n",
    "                \"Subject_Id\": subject_id,\n",
    "                \"Gender\": gender,\n",
    "                \"Class/ASD\": subject_group,\n",
    "                \"Family_History\": eligibility_1_3,\n",
    "                \"1st_Screening_ASD_Criteria\": eligibility_1_2,\n",
    "                \"Premature_Infant\": eligibility_1_4,\n",
    "                \"Lanuage_Delay\": eligibility_1_5,\n",
    "                \"2nd_Screening_ASD_Criteria\": eligibility_1_6,\n",
    "                \"Congenital_Genetic_Disorder\": eligibility_2_2,\n",
    "                \"History_of_Brain_Damage\": eligibility_2_3,\n",
    "                \"Seizure_or_Neurological_disease\": eligibility_2_4,\n",
    "            })\n",
    "\n",
    "    return survey_data\n",
    "\n",
    "def process_eligibility_criteria(df):\n",
    "    \"\"\"\n",
    "    Processes the eligibility criteria columns, converting '2' to '0' where applicable.\n",
    "    \"\"\"\n",
    "    criteria_columns = [\n",
    "        \"Family_History\", \"Premature_Infant\", \"Lanuage_Delay\",\n",
    "        \"1st_Screening_ASD_Criteria\", \"Congenital_Genetic_Disorder\",\n",
    "        \"History_of_Brain_Damage\", \"Seizure_or_Neurological_disease\"\n",
    "    ]\n",
    "    \n",
    "    if \"2nd_Screening_ASD_Criteria\" in df.columns:\n",
    "        criteria_columns.append(\"2nd_Screening_ASD_Criteria\")\n",
    "\n",
    "    for col in criteria_columns:\n",
    "        if col in df.columns:\n",
    "            if col == \"1st_Screening_ASD_Criteria\" and df['Class/ASD'].iloc[0] == '정상군':\n",
    "                df[col] = df[col].replace({'1': '0', '2': '1'})\n",
    "            else:\n",
    "                df[col] = df[col].replace({'2': '0'})\n",
    "    return df\n",
    "    \n",
    "def get_unique_survey_types(df):\n",
    "    \"\"\"\n",
    "    Returns a set of unique survey types present in the dataframe.\n",
    "    \"\"\"\n",
    "    survey_types = []\n",
    "    for index, row in df.iterrows():\n",
    "        survey_info = row['SurveyInfo']\n",
    "        for survey in survey_info:\n",
    "            survey_type = survey.get('CodeBookFormCd')\n",
    "            if survey_type:\n",
    "                survey_types.append(survey_type)\n",
    "    return set(survey_types)\n",
    "\n",
    "# # File paths\n",
    "# high_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_HIGH_20241004).json\"\n",
    "# asd_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_20241004).json\"\n",
    "# td_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(NORMAL_20241004).json\"\n",
    "\n",
    "# Load and process JSON files\n",
    "high_data = load_and_process_json_file(high_filepath, \"High\")\n",
    "asd_data = load_and_process_json_file(asd_filepath, \"ASD\")\n",
    "td_data = load_and_process_json_file(td_filepath, \"TD\")\n",
    "\n",
    "# Create dataframes\n",
    "df_high = pd.DataFrame(high_data)\n",
    "df_asd = pd.DataFrame(asd_data)\n",
    "df_td = pd.DataFrame(td_data)\n",
    "\n",
    "# Extract survey data\n",
    "high_survey_data = extract_survey_data(high_filepath, \"High\")\n",
    "asd_survey_data = extract_survey_data(asd_filepath, \"ASD\")\n",
    "td_survey_data = extract_survey_data(td_filepath, \"TD\")\n",
    "\n",
    "# Create dataframes from survey data\n",
    "High_Info = pd.DataFrame(high_survey_data)\n",
    "Asd_Info = pd.DataFrame(asd_survey_data)\n",
    "Normal_Info = pd.DataFrame(td_survey_data)\n",
    "\n",
    "# Process eligibility criteria\n",
    "High_Info = process_eligibility_criteria(High_Info)\n",
    "Asd_Info = process_eligibility_criteria(Asd_Info)\n",
    "Normal_Info = process_eligibility_criteria(Normal_Info)\n",
    "\n",
    "# Add class labels\n",
    "Asd_Info['class'] = 'asd'\n",
    "Normal_Info['class'] = 'td'\n",
    "High_Info['class'] = 'high'\n",
    "\n",
    "# Combine dataframes\n",
    "combined_info = pd.concat([Asd_Info, Normal_Info, High_Info])\n",
    "\n",
    "# Convert 'Subject_Id' column to string\n",
    "combined_info['Subject_Id'] = combined_info['Subject_Id'].astype(str)\n",
    "\n",
    "# Export to CSV\n",
    "# combined_info.to_csv('./patient_combined_info_1004_Oct23_refactored.csv', index=False)\n",
    "\n",
    "# Get unique survey types\n",
    "unique_survey_types_high = get_unique_survey_types(df_high)\n",
    "unique_survey_types_asd = get_unique_survey_types(df_asd)\n",
    "unique_survey_types_td = get_unique_survey_types(df_td)\n",
    "\n",
    "# Combine the dataframes\n",
    "df_combined = pd.concat([df_high, df_asd, df_td])\n",
    "\n",
    "# Get unique survey types from the combined dataframe\n",
    "unique_survey_types_combined = get_unique_survey_types(df_combined)\n",
    "\n",
    "# Print unique survey types (optional)\n",
    "print(\"Unique survey types (High):\", unique_survey_types_high)\n",
    "print(\"Unique survey types (ASD):\", unique_survey_types_asd)\n",
    "print(\"Unique survey types (TD):\", unique_survey_types_td)\n",
    "print(\"Unique survey types (Combined):\", unique_survey_types_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class/ASD\n",
       "ASD         525\n",
       "ASD_HIGH    471\n",
       "NORMAL      450\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_info['Class/ASD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# # File paths\n",
    "# high_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_HIGH_20241004).json\"\n",
    "# asd_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_20241004).json\"\n",
    "# td_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(NORMAL_20241004).json\"\n",
    "\n",
    "def load_and_process_scq_lifetime(filepath, group):\n",
    "    \"\"\"\n",
    "    Loads SCQ Lifetime data from a JSON file, filters for relevant questions,\n",
    "    and returns a dataframe with SubjectId, Question Responses, and Group.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    subject_ids = []\n",
    "    question_responses = [] \n",
    "\n",
    "    # SCQ Lifetime question numbers (1 to 40)\n",
    "    included_questions = {f'SCQ_LIFETIME_2448_{i}': str(i) for i in range(1, 41)}\n",
    "\n",
    "    for participant in data:\n",
    "        subject_id = participant[\"ParticipantInfo\"][\"SubjectId\"]\n",
    "        \n",
    "        for section in participant:\n",
    "            if section not in [\"ParticipantInfo\", \"DemographicData\"]:\n",
    "                for survey in participant[section]:\n",
    "                    if survey.get(\"CodeBookFormCd\") == \"SCQ_LIFETIME_2448\" and \"QuestionResult\" in survey:\n",
    "                        responses = {}\n",
    "                        for question in survey[\"QuestionResult\"]:\n",
    "                            if question[\"QuestionSeq\"] in included_questions:\n",
    "                                responses[included_questions[question[\"QuestionSeq\"]]] = question[\"AnswerValue\"]\n",
    "                        \n",
    "                        if responses:\n",
    "                            subject_ids.append(subject_id)\n",
    "                            question_responses.append(responses)\n",
    "\n",
    "    \n",
    "    scq_df = pd.DataFrame(question_responses)\n",
    "    scq_df.insert(0, \"SubjectId\", subject_ids) #insert at the 0th position\n",
    "    scq_df['Group'] = group\n",
    "\n",
    "    return scq_df\n",
    "\n",
    "def process_dataframe(df):\n",
    "    \"\"\"\n",
    "    Processes the dataframe: reorders columns and adds a class label.\n",
    "    \"\"\"\n",
    "    column_order = [\"SubjectId\"] + [str(i) for i in range(1, 41)] + [\"Group\"]\n",
    "    processed_df = df[column_order]\n",
    "\n",
    "    if \"Group\" in processed_df.columns:\n",
    "        processed_df = processed_df.rename(columns={'Group': 'class'})\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# Load and process data for each group\n",
    "high_data = load_and_process_scq_lifetime(high_filepath, \"high\")\n",
    "td_data = load_and_process_scq_lifetime(td_filepath, \"td\")\n",
    "asd_data = load_and_process_scq_lifetime(asd_filepath, \"asd\")\n",
    "\n",
    "# Process each dataframe\n",
    "SCQ_l_high = process_dataframe(high_data)\n",
    "SCQ_l_td = process_dataframe(td_data)\n",
    "SCQ_l_asd = process_dataframe(asd_data)\n",
    "\n",
    "# Combine dataframes\n",
    "combined_df = pd.concat([SCQ_l_asd, SCQ_l_td, SCQ_l_high])\n",
    "\n",
    "# Convert 'SubjectId' column to string\n",
    "combined_df['SubjectId'] = combined_df['SubjectId'].astype(str)\n",
    "\n",
    "# # Export to CSV\n",
    "# combined_df.to_csv('./SCQ_L_combined_df_1004_oct23F_refactored.csv', index=False)\n",
    "\n",
    "# print(\"Data preprocessing complete. CSV file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "asd     474\n",
       "td      390\n",
       "high    373\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCQ_l mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script preprocesses survey data from the Social Communication Questionnaire (SCQ) Lifetime assessment. It loads JSON files containing SCQ responses, filters for the 40 core SCQ questions, maps responses to binary values (0 or 1) based on specified scoring criteria, and generates symptom descriptions based on these mapped responses. The script creates new columns representing specific ASD-related symptoms and behaviors, populating them with descriptive text when a relevant symptom is indicated by the mapped response. It also generates a 'combined' column that concatenates all identified symptom descriptions for each subject, providing a comprehensive overview of their SCQ-based ASD characteristics. The output is a CSV file containing the mapped SCQ responses, individual symptom mappings, and the combined symptom description column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_SCQ_a_g= pd.read_csv('./SCQ_L_combined_df_20250102.csv',  dtype={'SubjectId': str})   # 1004\n",
    "# combined_df.to_csv('./SCQ_L_combined_df_20250102.csv', index=False)\n",
    "merged_df_SCQ = merged_df_SCQ_a_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_SCQ = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1023040831</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1023041001</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1723041002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1023041241</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1723041301</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>asd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SubjectId  1  2  3  4  5  6  7  8  9  ... 32 33 34 35 36 37 38 39 40 class\n",
       "0  1023040831  1  2  1  2  2  1  1  2  1  ...  1  1  1  1  1  1  2  1  2   asd\n",
       "1  1023041001  2  2  2  2  2  2  2  2  2  ...  1  1  2  2  2  1  2  2  1   asd\n",
       "2  1723041002  1  2  1  2  2  2  1  2  1  ...                              asd\n",
       "3  1023041241  1  2  1  2  2  2  2  1  1  ...  1  1  2  2  1  2  2  2  2   asd\n",
       "4  1723041301  2                    1  2  ...  1  2  2  1  2  2  1  1  2   asd\n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_SCQ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column_based_on_condition(df, new_column, condition_column, condition, text):\n",
    "    df[new_column] = [text if str(x) == str(condition) else '' for x in df[condition_column]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all together for model building\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A1_C0233741', '1', 2, 'delayed phrases')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A2_C2371358', '2', 2, 'sustaining a conversation')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A2_C0566093', '2', 2, 'difficulty sustaining conversation')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A3_C0517108', '3', 1, 'repeated certain words over and over')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A4_C4036182', '4', 1, 'inappropriate questions or statements')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A5_C2183452', '5', 1, 'difficulty understanding appropriate use of pronouns and speaking')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A5_C2018039', '5', 1, 'first and second person confusion after phrase speech established')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A6_C2010447', '6', 1, 'occasional use of neologisms or idiosyncratic words and phrases')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A7_C2018029', '7', 1, 'speech fluency word repetition')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A8_C0475222', '8', 1, 'ritualistic behavior (qualifier value)')\n",
    "# A9\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A9_C4062278', '9', 1, 'facial expressions obviously inappropriate in several different situations')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A9_C0015457', '9', 1, 'inappropriate facial expressions')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A9_C4062278', '9', 2, 'facial expressions almost always appropriate to mood situation and context')\n",
    "# A10\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A10_C0422881', '10', 1, 'uses hand as tool')\n",
    "erged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A10_C0374529', '10', 1, 'occasional placement of others hand as a tool')\n",
    "# A11\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A11_C0543488', '11', 1, 'shows one or two unusual interests regularly')\n",
    "# A12\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A12_C0517073', '12', 1, 'shows unusual interest in toys')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A12_C0577474', '12', 1, 'toys used in purposeful manner')\n",
    "\n",
    "#A13\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A13_C3162300', '13', 2, 'behavior is peer group influenced')\n",
    "#A14\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A14_C0543488', '14', 1, 'unusual sensory interests')\n",
    "#A15\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A15_C0239842', '15', 1, 'occasional hand and finger mannerisms')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A15_C4065487', '15', 1, 'some stereotypic hand movements were observed')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A15_C0038273', '15', 1, 'stereotypic finger movements')\n",
    "#A16\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A16_C0562472', '16', 1, 'repetitive complex twisting movements of whole body')\n",
    "merged_df_SCQ2 = add_column_based_on_condition(merged_df_SCQ, 'A16_C0562461', '16', 1, 'repetitive spinning movements')\n",
    "#A17\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A17_C0085271', '17', 1, 'deliberate self-harm')\n",
    "#A18\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A18_C0233715', '18', 1, 'subject has a fascination with objects')\n",
    "#A19\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A19_C0517164', '19', 1, 'develops close friendships')\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A19_C0679458', '19', 2, 'lack of close friend')\n",
    "#A20\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A20_C0037420', '20', 1, 'is seeking social interactions')\n",
    "#A21\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A21_C218341', '21', 1, 'some indication of spontaneous imitation that goes beyond copying a frequent use of an object')\n",
    "#A22\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A22_C4036288', '22', 1, 'spontaneously pointing')\n",
    "#A23\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A23_C0017510', '23', 1, 'gestures')\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A23_C2317765', '23', 2, 'does not use gestures to communicate')\n",
    "#A24\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A24_C0549240', '24', 1, 'head-nodding')\n",
    "#A25\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A25_C3669952', '25', 1, 'head shaking')\n",
    "#A26\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A26_C0870532', '26', 2, 'subject avoided eye contact with examiner')\n",
    "#A27\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A27_C3853123', '27', 1, 'some evidence of reciprocal social smiling')\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A27_C3846646', '27', 2, 'little or no smiling at people')\n",
    "\n",
    "#A28\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A28_C4064666', '28', 2, 'rare or no social approaches of showing and directing attention')\n",
    "#A29\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A29_C0237876', '29', 1, 'sharing social behavior')\n",
    "#A30\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A30_C2317765', '30', 2, 'did not actively engage with this examiner')\n",
    "\n",
    "#A31\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A31_C0221736', '31', 1, 'emotional reactions')\n",
    "#A32\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A32_C0564221', '32', 2, 'difficulty asking questions')\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A32_C3824925', '32', 1, 'body language in children')\n",
    "#A33\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A33_C0015457', '33', 2, 'somewhat limited facial expression range')\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A33_C4062225', '33', 1, 'range of facial expressions used to communicate')\n",
    "\n",
    "#A34\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A34_C0015457', '34', 2, 'no clear history of interactive play with other children')\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A34_C1822065', '34', 1, 'engaging in social play')\n",
    "#A35\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A35_C1822065', '35', 2, 'little evidence of pretend play')\n",
    "#A36\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A36_C0814594', '36', 2, 'uninterested in interacting with other children')\n",
    "\n",
    "#A37\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A37_C0548554', '37', 1, 'response to approaches of other children')\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A37_C0474413', '37', 2, 'consistently and persistently avoids approaches of other children')\n",
    "#A38\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A38_C2317765', '38', 2, 'usually does not look up or pay attention when spoken to')\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A38_C1619754', '38', 1, 'usually looks up and pays attention when spoken to')\n",
    "#A39\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A39_C1822065', '39', 1, 'imaginative cooperative play with other children in spontaneous pretend activities')\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A39_C4064319', '39', 1, 'subject does engage in interactive play with other children easily')\n",
    "#A40\n",
    "merged_df_SCQ2= add_column_based_on_condition(merged_df_SCQ, 'A40_C0548554', '40', 2, 'seeks no play that involves participation in groups of other children')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A1_C0233741', 'A2_C2371358', 'A2_C0566093', 'A3_C0517108',\n",
      "       'A4_C4036182', 'A5_C2183452', 'A5_C2018039', 'A6_C2010447',\n",
      "       'A7_C2018029', 'A8_C0475222', 'A9_C4062278', 'A9_C0015457',\n",
      "       'A10_C0422881', 'A10_C0374529', 'A11_C0543488', 'A12_C0517073',\n",
      "       'A12_C0577474', 'A13_C3162300', 'A14_C0543488', 'A15_C0239842',\n",
      "       'A15_C4065487', 'A15_C0038273', 'A16_C0562472', 'A16_C0562461',\n",
      "       'A17_C0085271', 'A18_C0233715', 'A19_C0517164', 'A19_C0679458',\n",
      "       'A20_C0037420', 'A21_C218341', 'A22_C4036288', 'A23_C0017510',\n",
      "       'A23_C2317765', 'A24_C0549240', 'A25_C3669952', 'A26_C0870532',\n",
      "       'A27_C3853123', 'A27_C3846646', 'A28_C4064666', 'A29_C0237876',\n",
      "       'A30_C2317765', 'A31_C0221736', 'A32_C0564221', 'A32_C3824925',\n",
      "       'A33_C0015457', 'A33_C4062225', 'A34_C0015457', 'A34_C1822065',\n",
      "       'A35_C1822065', 'A36_C0814594', 'A37_C0548554', 'A37_C0474413',\n",
      "       'A38_C2317765', 'A38_C1619754', 'A39_C1822065', 'A39_C4064319',\n",
      "       'A40_C0548554'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Combine text descriptions into a single column\n",
    "T_ASD_SCQ = merged_df_SCQ2\n",
    "# T_ASD_SCQ['combined'] = T_ASD_SCQ.apply(lambda row: \", \".join(\n",
    "#     str(val) for col, val in row.items() if col.startswith('A') and val != ''\n",
    "# ), axis=1)\n",
    "print(T_ASD_SCQ.columns[42:99])\n",
    "T_ASD_SCQ['combined'] = T_ASD_SCQ[T_ASD_SCQ.columns[42:99]].apply(lambda x: \" ,\".join(x.astype(str)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language Delay preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script preprocesses language assessment data from SELSI and PRES instruments to identify potential language delays in children. It handles JSON files containing survey responses, extracts relevant fields (Subject ID, age, test scores), cleans and standardizes the data, and calculates the difference between chronological age and language developmental age. A language delay label ('yes' or 'no') is assigned based on a 7-month or greater delay in either receptive or expressive language. The script outputs two preprocessed CSV files (one for SELSI and one for PRES) containing the calculated language delay information, ready for further analysis or integration with other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='3' # Set the GPU 2 to use\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths and their respective class labels\n",
    "files_and_labels = [\n",
    "    ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/20250102/Survey/T_SurveySatus(NORMAL).json', 'TD'),\n",
    "    ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/20250102/Survey/T_SurveySatus(ASD_HIGH).json', 'High'),\n",
    "    ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/20250102/Survey/T_SurveySatus(ASD).json', 'ASD')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_survey(file_path, class_label):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data_json = json.load(file)\n",
    "\n",
    "    survey_data = []\n",
    "    for entry in data_json:\n",
    "        subject_id = entry['ParticipantInfo']['SubjectId']\n",
    "        gender = entry['ParticipantInfo'].get('Gender', 'Unknown')  # Get gender, default to 'Unknown' if not present\n",
    "\n",
    "        for survey in entry['SurveyInfo']:\n",
    "            if survey['SurveyKindCd'] == \"PRES\":\n",
    "                pres_1848_1_1 = ''\n",
    "                pres_1848_2_1 = ''\n",
    "                for question in survey['QuestionResult']:\n",
    "                    if question['QuestionSeq'] == \"PRES_1848_1_1\":\n",
    "                        pres_1848_1_1 = question['AnswerValue']\n",
    "                    if question['QuestionSeq'] == \"PRES_1848_2_1\":\n",
    "                        pres_1848_2_1 = question['AnswerValue']\n",
    "\n",
    "                survey_data.append({\n",
    "                    \"SubjectId\": subject_id,\n",
    "                    \"Gender\": gender,\n",
    "                    \"Class\": class_label,\n",
    "                    \"CodeBookFormCd\": survey['CodeBookFormCd'],\n",
    "                    \"SurveyType\": survey['SurveyKindCd'],\n",
    "                    \"SubjectMonthAge\": survey['SubjectMonthAge'],\n",
    "                    \"InspectDate\": survey['InspectDate'],\n",
    "                    # PRES Questions\n",
    "                    \"1-1.\": pres_1848_1_1,\n",
    "                    \"2-1.\": pres_1848_2_1\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(survey_data)\n",
    "\n",
    "# # File paths and their respective class labels\n",
    "# files_and_labels = [\n",
    "#     # ('/home/skbae/ASD_DATA/20240705/E_설문지/1.정상.json', 'TD'),\n",
    "#     # ('/home/skbae/ASD_DATA/20240705/E_설문지/2.고위험.json', 'High'),\n",
    "#     # ('/home/skbae/ASD_DATA/20240705/E_설문지/3.자폐.json', 'ASD')\n",
    "# #     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/0809/Survey/T_SurveySatus(ASD_20240807).json', 'ASD'),\n",
    "# #     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/0809/Survey/T_SurveySatus(ASD_HIGH_20240807).json', 'High'),\n",
    "# #     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/0809/Survey/T_SurveySatus(NORMAL_20240807).json', 'TD')\n",
    "\n",
    "# # ]\n",
    "# # files_and_labels = \n",
    "#     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(NORMAL_20241004).json', 'TD'),   \n",
    "#     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_HIGH_20241004).json', 'High'), #\n",
    "#     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_20241004).json', 'ASD') #\n",
    "# ]\n",
    "\n",
    "# Load, process each file with its label, and concatenate into a single DataFrame\n",
    "data_frames = [load_and_process_survey(path, label) for path, label in files_and_labels]\n",
    "PRES = pd.concat(data_frames)\n",
    "PRES.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRES['1-1.'] = PRES['1-1.'].apply(lambda x: x.replace('개월', '') if isinstance(x, str) and '개월' in x else x)\n",
    "PRES['2-1.'] = PRES['2-1.'].apply(lambda x: x.replace('개월', '') if isinstance(x, str) and '개월' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new columns '수용언어_diff' and '표현언어_diff' initialized with default values\n",
    "PRES['수용언어_diff'] = 0  # Initialize with 0 or any other default value or calculation\n",
    "PRES['표현언어_diff'] = 0  # Initialize with 0 or any other default value or calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_numeric_in_column = PRES['2-1.'].apply(lambda x: not x.isnumeric())\n",
    "# PRES[non_numeric_in_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터링 조건 생성\n",
    "condition_1 = PRES['1-1.'].apply(lambda x: x.isnumeric())\n",
    "condition_2 = PRES['2-1.'].apply(lambda x: x.isnumeric())\n",
    "# 두 조건을 결합하여 숫자가 아닌 행 제거\n",
    "PRES2 = PRES[condition_1 | condition_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert Columns to int\n",
    "# PRES2['SubjectMonthAge'] = pd.to_numeric(PRES2['SubjectMonthAge'], errors='coerce')\n",
    "# PRES2['1-1.'] = pd.to_numeric(PRES2['1-1.'], errors='coerce')\n",
    "# PRES2['2-1.'] = pd.to_numeric(PRES2['2-1.'], errors='coerce')\n",
    "\n",
    "# # 수용언어 Difference Value\n",
    "# PRES2['수용언어_diff'] = PRES2['SubjectMonthAge'] - PRES2['1-1.']\n",
    "\n",
    "# # 표현언어 Difference Value\n",
    "# PRES2['표현언어_diff'] = PRES2['SubjectMonthAge'] - PRES2['2-1.']\n",
    "# PRES2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRES2['language_label'] = np.where((PRES2['수용언어_diff'] >= 7) | (PRES2['표현언어_diff'] >= 7), 'yes', 'no')\n",
    "# PRES2.to_csv('./PRES2_LD_1004_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELSI\n",
    "\n",
    "def load_and_process_survey(file_path, class_label):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data_json = json.load(file)\n",
    "\n",
    "    survey_data = []\n",
    "    for entry in data_json:\n",
    "        subject_id = entry['ParticipantInfo']['SubjectId']\n",
    "        gender = entry['ParticipantInfo'].get('Gender', 'Unknown')  # Get gender, default to 'Unknown' if not present\n",
    "\n",
    "        for survey in entry['SurveyInfo']:\n",
    "            if survey['SurveyKindCd'] == \"SELSI\":\n",
    "                selsi_1848_2_2 = ''\n",
    "                selsi_1848_3_2 = ''\n",
    "                for question in survey['QuestionResult']:\n",
    "                    if question['QuestionSeq'] == \"SELSI_1848_2_2\":\n",
    "                        selsi_1848_2_2 = question['AnswerValue']\n",
    "                    if question['QuestionSeq'] == \"SELSI_1848_3_2\":\n",
    "                        selsi_1848_3_2 = question['AnswerValue']\n",
    "\n",
    "                survey_data.append({\n",
    "                    \"SubjectId\": subject_id,\n",
    "                    \"Gender\": gender,\n",
    "                    \"Class\": class_label,\n",
    "                    \"CodeBookFormCd\": survey['CodeBookFormCd'],\n",
    "                    \"SurveyType\": survey['SurveyKindCd'],\n",
    "                    \"SubjectMonthAge\": survey['SubjectMonthAge'],\n",
    "                    \"InspectDate\": survey['InspectDate'],\n",
    "                    # SELSI Questions\n",
    "                    \"2-2.\": selsi_1848_2_2,\n",
    "                    \"3-2.\": selsi_1848_3_2\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(survey_data)\n",
    "\n",
    "# File paths and their respective class labels\n",
    "# files_and_labels = [\n",
    "#     # ('/home/skbae/ASD_DATA/20240705/E_설문지/1.정상.json', 'TD'),\n",
    "#     # ('/home/skbae/ASD_DATA/20240705/E_설문지/2.고위험.json', 'High'),\n",
    "#     # ('/home/skbae/ASD_DATA/20240705/E_설문지/3.자폐.json', 'ASD')\n",
    "# #     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/0809/Survey/T_SurveySatus(ASD_20240807).json', 'ASD'),\n",
    "# #     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/0809/Survey/T_SurveySatus(ASD_HIGH_20240807).json', 'High'),\n",
    "# #     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/0809/Survey/T_SurveySatus(NORMAL_20240807).json', 'TD')\n",
    "\n",
    "# # ]\n",
    "# # # File paths and their respective class labels\n",
    "# # files_and_labels = \n",
    "#     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(NORMAL_20241004).json', 'TD'),   \n",
    "#     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_HIGH_20241004).json', 'High'), #\n",
    "#     ('/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_20241004).json', 'ASD') #\n",
    "# ]\n",
    "\n",
    "# Load, process each file with its label, and concatenate into a single DataFrame\n",
    "data_frames = [load_and_process_survey(path, label) for path, label in files_and_labels]\n",
    "SELSI = pd.concat(data_frames)\n",
    "SELSI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELSI['2-2.'] = SELSI['2-2.'].apply(lambda x: x.replace('개월', '') if isinstance(x, str) and '개월' in x else x)\n",
    "SELSI['3-2.'] = SELSI['3-2.'].apply(lambda x: x.replace('개월', '') if isinstance(x, str) and '개월' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELSI['2-2.'] = SELSI['2-2.'].apply(lambda x: x.replace('점', '') if isinstance(x, str) and '점' in x else x)\n",
    "SELSI['3-2.'] = SELSI['3-2.'].apply(lambda x: x.replace('점', '') if isinstance(x, str) and '점' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new columns '수용언어_diff' and '표현언어_diff' initialized with default values\n",
    "SELSI['수용언어_diff'] = 0  # Initialize with 0 or any other default value or calculation\n",
    "SELSI['표현언어_diff'] = 0  # Initialize with 0 or any other default value or calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 조건에 맞는 값을 30으로 대체\n",
    "SELSI['2-2.'] = SELSI['2-2.'].replace(['29↑', '>29', '29>', '29 이상','29 이상 ', '29 초과'], '30')\n",
    "SELSI['3-2.'] = SELSI['3-2.'].replace(['29↑', '>29', '29>', '29 이상', '29 이상 ','29 초과'], '30')\n",
    "\n",
    "# 특정 조건에 맞는 값을 31로 대체\n",
    "SELSI['2-2.'] = SELSI['2-2.'].replace(['30 이상', '30 초과', '30↑'], '31')\n",
    "SELSI['3-2.'] = SELSI['3-2.'].replace(['30 이상', '30 초과', '30↑'], '31')\n",
    "\n",
    "# 결과 출력\n",
    "# print(SELSI['2-2.'].value_counts())\n",
    "# print(SELSI['3-2.'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_in_column = SELSI['2-2.'].apply(lambda x: not x.isnumeric())\n",
    "SELSI[non_numeric_in_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_in_column = SELSI['3-2.'].apply(lambda x: not x.isnumeric())\n",
    "SELSI[non_numeric_in_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Columns to int\n",
    "SELSI['SubjectMonthAge'] = pd.to_numeric(SELSI['SubjectMonthAge'], errors='coerce')\n",
    "SELSI['2-2.'] = pd.to_numeric(SELSI['2-2.'], errors='coerce')\n",
    "SELSI['3-2.'] = pd.to_numeric(SELSI['3-2.'], errors='coerce')\n",
    "\n",
    "# 수용언어 Difference Value\n",
    "SELSI['수용언어_diff'] = SELSI['SubjectMonthAge'] - SELSI['2-2.']\n",
    "\n",
    "# 표현언어 Difference Value\n",
    "SELSI['표현언어_diff'] = SELSI['SubjectMonthAge'] - SELSI['3-2.']\n",
    "SELSI.reset_index(drop=True, inplace=True)\n",
    "SELSI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELSI['language_label'] = np.where((SELSI['수용언어_diff'] >= 7) | (SELSI['표현언어_diff'] >= 7), 'yes', 'no')\n",
    "# SELSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Language_delay = pd.concat([PRES2, SELSI], ignore_index=True)\n",
    "Language_delay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Language_delay.to_csv('./language_delay_20250102_Data_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class  language_label\n",
       "ASD    yes               375\n",
       "       no                135\n",
       "High   no                304\n",
       "       yes               157\n",
       "TD     no                435\n",
       "       yes                27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Language_delay.groupby('Class')['language_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복된 SubjectId 제거 및 language_label이 'yes'인 경우 language_delay를 'Yes'로 설정\n",
    "def determine_language_delay(group):\n",
    "    if 'yes' in group['language_label'].values:\n",
    "        group['language_delay'] = 'yes'\n",
    "    else:\n",
    "        group['language_delay'] = 'no'\n",
    "    return group.iloc[0]\n",
    "\n",
    "Language_delay2 = Language_delay.groupby('SubjectId').apply(determine_language_delay).reset_index(drop=True)\n",
    "\n",
    "# 필요한 열만 선택\n",
    "Language_delay2 = Language_delay2[['SubjectId', 'Gender', 'Class', 'SubjectMonthAge',  'language_delay']]  # 'SurveyType', 'SubjectMonthAge', '수용언어_diff', '표현언어_diff', 'language_label', 'language_delay']]\n",
    "\n",
    "# 결과 출력\n",
    "print(len(Language_delay2))\n",
    "print(Language_delay2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Language_delay2['language_delay'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Language_delay2.to_csv('./language_delay2_20250102_Data_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete. CSV files saved.\n"
     ]
    }
   ],
   "source": [
    "# # Save the processed data\n",
    "# SELSI.to_csv('./SELSI_LD_20250102_Data_preprocessed.csv', index=False)\n",
    "# PRES.to_csv('./PRES_LD_20250102_Data_preprocessed.csv', index=False)\n",
    "\n",
    "# print(\"Data preprocessing complete. CSV files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRES Language Delay Counts\n",
      "language_label\n",
      "no     623\n",
      "yes    200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "PRESdelay_counts = PRES2['language_label'].value_counts()\n",
    "# Printing the counts\n",
    "print (\"PRES Language Delay Counts\")\n",
    "print(PRESdelay_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Language_delay = pd.concat([PRES2, SELSI], ignore_index=True)\n",
    "Language_delay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Language_delay ))\n",
    "Language_delay.to_csv('./language_delay_20250103_Data_0106.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCHAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script preprocesses survey data from the Modified Checklist for Autism in Toddlers (M-CHAT) assessment. It loads JSON files containing M-CHAT responses for different groups (High-risk, TD, ASD), extracts relevant fields (Subject ID, responses to the 23 M-CHAT questions), and maps responses to binary values (0 or 1) based on specified scoring criteria. It then generates symptom descriptions based on these mapped responses, creating new columns for each symptom and populating them with descriptive text when a relevant symptom is indicated. The script also creates a 'combined' column that concatenates all identified symptom descriptions for each subject, providing a comprehensive overview of their M-CHAT-based characteristics. The output is a CSV file containing the mapped M-CHAT responses, individual symptom mappings, the combined symptom description column, and the subject's assigned class (group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_obj = '/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/20250102/M-CHAT/' # Added path for JSON files\n",
    "\n",
    "# Load JSON data for each group (High-risk, TD, ASD) \n",
    "df_HR = pd.read_json(pt_obj + \"T_MCHAT(ASD_HIGH).json\")\n",
    "df_TD = pd.read_json(pt_obj + \"T_MCHAT(NORMAL).json\")\n",
    "df_ASD = pd.read_json(pt_obj + \"T_MCHAT(ASD).json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# # pt0 = '/home/skbae/Documents/skbae/ASD/Kaggle_ASD_TD/Data/'  # Original path (seems incorrect for this task)\n",
    "# pt0 = '/home/skbae/Documents/skbae/ASD/PJT_Data/Questions/Import'  # Corrected path based on your file structure\n",
    "# pt_obj = '/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/M-CHAT/' # Added path for JSON files\n",
    "\n",
    "# # Load M-CHAT mapping data (for reference, not directly used in the main processing logic)\n",
    "# MCHAT_ASD_T = pd.read_csv(pt0 + \"/MCHAT_Mapping_import_F_jan242024.csv\", encoding='utf-8')\n",
    "\n",
    "# # Load JSON data for each group (High-risk, TD, ASD) - 1004 data\n",
    "# df_HR = pd.read_json(pt_obj + \"T_MCHAT(ASD_HIGH_20241004).json\")\n",
    "# df_TD = pd.read_json(pt_obj + \"T_MCHAT(NORMAL_20241004).json\")\n",
    "# df_ASD = pd.read_json(pt_obj + \"T_MCHAT(ASD_20241004).json\")\n",
    "\n",
    "# Select relevant columns and rename 'projectSeq' to 'Class'\n",
    "data_HR = df_HR[['subjectId', 'mchartId', 'orgId', 'patientSeq', 'projectSeq', 'result', 'note', 'gender', 'registDt']]\n",
    "data_TD = df_TD[['subjectId', 'mchartId', 'orgId', 'patientSeq', 'projectSeq', 'result', 'note', 'gender', 'registDt']]\n",
    "data_ASD = df_ASD[['subjectId', 'mchartId', 'orgId', 'patientSeq', 'projectSeq', 'result', 'note', 'gender', 'registDt']]\n",
    "\n",
    "# data_HR.columns = ['SubjectId', 'MchartId', 'OrgId', 'PatientSeq', 'Class', 'Result', 'note', 'gender', 'RegistDt']\n",
    "# data_TD.columns = ['SubjectId', 'MchartId', 'OrgId', 'PatientSeq', 'Class', 'Result', 'note', 'gender', 'RegistDt']\n",
    "# data_ASD.columns = ['SubjectId', 'MchartId', 'OrgId', 'PatientSeq', 'Class', 'Result', 'note', 'gender', 'RegistDt']\n",
    "\n",
    "# Concatenate dataframes and reset index\n",
    "# data_total = pd.concat([data_HR, data_TD, data_ASD]).reset_index(drop=True)\n",
    "data_total = pd.concat([data_HR,data_TD,data_ASD])\n",
    "data_total.columns = ['SubjectId','MchartId','OrgId','PatientSeq','Class','Result','note','gender','RegistDt']\n",
    "data_total=data_total.reset_index()\n",
    "\n",
    "\n",
    "# Split the 'Result' column\n",
    "split_results = data_total['Result'].str.split(',', expand=True)\n",
    "# Rename the columns of the split results\n",
    "split_results.columns = [f\"Result_{i}\" for i in range(1, split_results.shape[1] + 1)]\n",
    "# Drop the original 'Result' column and concatenate the split results\n",
    "data_total = data_total.drop('Result', axis=1).join(split_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total['A1_C0030540']=['problem parent-child' if x == '1' else '' for x in data_total['Result_1']]\n",
    "#0: yes, 1: No - need to change the below\n",
    "data_total['A2_C3476168']=['does not play with other children' if x == '1' else '' for x in data_total['Result_2']]\n",
    "data_total['A3_C0239067']=['difficulty walking up stairs' if x == '1' else '' for x in data_total['Result_3']]\n",
    "data_total['A4_C2317765']=['does not seek out contact with other children' if x == '1' else '' for x in data_total['Result_4']]\n",
    "data_total['A5_C2371970']=['learning through pretend play' if x =='0' else '' for x in data_total['Result_5']] #1 positive\n",
    "data_total['A6_C2317765']=['does not use gestures to communicate' if x == '1' else '' for x in data_total['Result_6']]\n",
    "\n",
    "#0: yes, 1: No - need to change the below\n",
    "data_total['A7_C2317765']=['does not play with other children' if x == '1' else '' for x in data_total['Result_7']]\n",
    "data_total['A8_C0032214']=['no play' if x == '1' else '' for x in data_total['Result_8']]\n",
    "data_total['A9_C0030542']=['parent-child relationships' if x == '0' else '' for x in data_total['Result_9']] #1 positive \n",
    "data_total['A9_C4064319']=['does not play with others' if x == '1' else '' for x in data_total['Result_9']] #1 positive \n",
    "data_total['A10_C0562122']=['does not establish eye contact' if x =='1' else '' for x in data_total['Result_10']]\n",
    "data_total['A11_C3710336']=['definite sensitivity to noises that are not distressing to most other people' if x == '1' else '' for x in data_total['Result_11']] # 1 not ok\n",
    "\n",
    "\n",
    "#0: yes, 1: No - need to change the below\n",
    "data_total['A12_C2198595']=['has a social smile' if x == '0' else '' for x in data_total['Result_12']]\n",
    "data_total['A12_C3258117']=['response delay' if x == '1' else '' for x in data_total['Result_12']]\n",
    "data_total['A13_C3710336']=['atypical child with whom to interact' if x == '1' else '' for x in data_total['Result_13']]\n",
    "data_total['A13_C0518134']=['interacts positively with child' if x == '0' else '' for x in data_total['Result_13']]\n",
    "data_total['A14_C2317765']=['does not appropriately respond verbally' if x == '1' else '' for x in data_total['Result_14']]\n",
    "data_total['A15_C0558182']=['does not interact with peers' if x =='1' else '' for x in data_total['Result_15']]\n",
    "data_total['A16_C0560046']=['unable to walk finding' if x == '1' else '' for x in data_total['Result_16']]\n",
    "\n",
    "#0: yes, 1: No - need to change the below\n",
    "data_total['A17_C3710336']=['atypical child with whom to interact' if x == '1' else '' for x in data_total['Result_17']]\n",
    "data_total['A18_C0562470']=['repetitive finger movements' if x == '1' else '' for x in data_total['Result_18']]\n",
    "data_total['A19_C4064319']=['does not play with others' if x == '1' else '' for x in data_total['Result_19']]\n",
    "data_total['A20_C4064026']=['social/emotional reciprocity appears deaf' if x =='1' else '' for x in data_total['Result_20']] # 1 not ok\n",
    "data_total['A21_C3166351']=['speech difficult to understand' if x == '1' else '' for x in data_total['Result_21']]\n",
    "data_total['A22_C0700075']=['motor restlessness' if x =='1' else '' for x in data_total['Result_22']] # 1 not ok\n",
    "data_total['A23_C4064319']=['does not play with others' if x == '1' else '' for x in data_total['Result_23']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_ASD['combined']=T_ASD[[T_ASD.columns[32],T_ASD.columns[33],T_ASD.columns[34],\\\n",
    "                        T_ASD.columns[35],T_ASD.columns[36],T_ASD.columns[37],T_ASD.columns[38],T_ASD.columns[39],\\\n",
    "                        T_ASD.columns[40],T_ASD.columns[41],T_ASD.columns[42],T_ASD.columns[43],T_ASD.columns[44],\\\n",
    "                        T_ASD.columns[45],T_ASD.columns[46],T_ASD.columns[47],T_ASD.columns[48],T_ASD.columns[49],\\\n",
    "                        T_ASD.columns[50],T_ASD.columns[51],T_ASD.columns[52],T_ASD.columns[53],T_ASD.columns[54],\\\n",
    "                        T_ASD.columns[55],T_ASD.columns[56],T_ASD.columns[57]]].apply(lambda x: \" ,\".join(x), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M-CHAT data preprocessing complete. CSV file saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the preprocessed data\n",
    "T_ASD.to_csv('./MCHAT_data_total_20250102_preprocessed.csv', header=True, index=False)\n",
    "\n",
    "print(\"M-CHAT data preprocessing complete. CSV file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "2    193\n",
       "1    136\n",
       "3     99\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_ASD['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script preprocesses survey data from the Social Responsiveness Scale (SRS) assessment. It loads JSON files containing SRS responses, filters for the 65 SRS questions, maps responses to binary values (0 or 1) based on specified scoring criteria (1, 2 map to 0; 3, 4 map to 1), and generates symptom descriptions based on these mapped responses. The script creates new columns representing specific ASD-related symptoms and behaviors, populating them with descriptive text when a relevant symptom is indicated by the mapped response. It also generates a 'combined' column that concatenates all identified symptom descriptions for each subject, providing a comprehensive overview of their SRS-based ASD characteristics. The output is a CSV file containing the mapped SRS responses, individual symptom mappings, and the combined symptom description column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths and group labels\n",
    "# high_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_HIGH_20241004).json\"\n",
    "# asd_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(ASD_20241004).json\"\n",
    "# td_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/1004/Survey/T_SurveySatus(NORMAL_20241004).json\"\n",
    "#20250102\n",
    "high_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/20250102/Survey/T_SurveySatus(ASD_HIGH).json\"\n",
    "asd_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/20250102/Survey/T_SurveySatus(ASD).json\"\n",
    "td_filepath = \"/home/skbae/Documents/skbae/ASD/PJT_Data/Object_Storage/Data/Questions/20250102/Survey/T_SurveySatus(NORMAL).json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without considering trialindex ==1\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_process_json_file(filepath, group):\n",
    "    # Load JSON data from the file\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Initialize lists to hold extracted data\n",
    "    subject_ids = []\n",
    "    question_seqs = []\n",
    "    answer_values = []\n",
    "\n",
    "    # List of question sequences to include\n",
    "    included_questions = {f'SRS2_3048_{i}': str(i) for i in range(1, 66)} #SRS2_3048 66,SCQ_LIFETIME_2448\n",
    "\n",
    "    # Extract data from JSON\n",
    "    for participant in data:\n",
    "        subject_id = participant[\"ParticipantInfo\"][\"SubjectId\"]\n",
    "        # Iterate over sections that contain survey results\n",
    "        for section in participant:\n",
    "            # Skip ParticipantInfo and DemographicData as they don't contain \"QuestionResult\"\n",
    "            if section not in [\"ParticipantInfo\", \"DemographicData\"]:\n",
    "                for survey in participant[section]:\n",
    "                    # Check if the survey is KQCHAT\n",
    "                    if survey.get(\"CodeBookFormCd\") == \"SRS2_3048\" and \"QuestionResult\" in survey:\n",
    "                        for question in survey[\"QuestionResult\"]:\n",
    "                            if question[\"QuestionSeq\"] in included_questions:\n",
    "                                subject_ids.append(subject_id)\n",
    "                                question_seqs.append(included_questions[question[\"QuestionSeq\"]])\n",
    "                                answer_values.append(question[\"AnswerValue\"])\n",
    "\n",
    "    # Create intermediate DataFrame\n",
    "    intermediate_df = pd.DataFrame({\n",
    "        \"SubjectId\": subject_ids,\n",
    "        \"QuestionSeq\": question_seqs,\n",
    "        \"AnswerValue\": answer_values,\n",
    "        \"Group\": [group] * len(subject_ids)  # Add group column\n",
    "    })\n",
    "\n",
    "    return intermediate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df):\n",
    "    # 중복 항목 제거\n",
    "    df = df.drop_duplicates(subset=[\"SubjectId\", \"QuestionSeq\"])\n",
    "\n",
    "    # Pivot the DataFrame to get the desired format\n",
    "    pivot_df = df.pivot(index=\"SubjectId\", columns=\"QuestionSeq\", values=\"AnswerValue\").reset_index()\n",
    "\n",
    "    # Create a list of column names\n",
    "    column_order = [\"SubjectId\"] + [str(i) for i in range(1, 66)]\n",
    "\n",
    "    # Select the desired columns\n",
    "    processed_df = pivot_df[column_order]\n",
    "\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and process each group\n",
    "high_data = load_and_process_json_file(high_filepath, \"High\")\n",
    "asd_data = load_and_process_json_file(asd_filepath, \"ASD\")\n",
    "td_data = load_and_process_json_file(td_filepath, \"TD\")\n",
    "\n",
    "# Process each DataFrame individually\n",
    "SRS_high = process_dataframe(high_data)\n",
    "SRS_asd = process_dataframe(asd_data)\n",
    "SRS_td = process_dataframe(td_data)\n",
    "\n",
    "# Add class labels\n",
    "SRS_high['class'] = 'high'\n",
    "SRS_asd['class'] = 'asd'\n",
    "SRS_td['class'] = 'td'\n",
    "\n",
    "# Combine all dataframes into a single DataFrame\n",
    "combined_df = pd.concat([SRS_high, SRS_asd, SRS_td])\n",
    "\n",
    "# Ensure 'SubjectId' is a string\n",
    "combined_df['SubjectId'] = combined_df['SubjectId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089\n"
     ]
    }
   ],
   "source": [
    "combined_df.columns\n",
    "print(len(combined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASD term mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column_based_on_condition2(df, new_column, condition_column, condition, text):\n",
    "    df[new_column] = [text if str(x) == str(condition) else '' for x in df[condition_column]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_asd_terms(df):\n",
    "    \"\"\"\n",
    "    Maps specific ASD-related terms based on pre-defined conditions and adds these mappings as new columns.\n",
    "    \"\"\"\n",
    "    term_conditions = [\n",
    "        ('A1_C0237280', '1', 1, 'restless behavior'),\n",
    "        ('A1_C0037397', '1', 0, 'initiates social behavior with individuals'),\n",
    "        ('A2_C2009191', '2', 1, 'facial expression is lacking for any social interchange'),\n",
    "        ('A3_C0558182', '3', 1, 'ability to interact with others'),\n",
    "        ('A4_C2165331', '4', 1, 'demonstrated behavior multiple patterns'),\n",
    "        ('A5_C4064023', '5', 1, 'social/emotional reciprocity lacks knowledge of appropriate social behavior'),\n",
    "        ('A6_C3476168', '6', 1, 'prefers to play alone'),\n",
    "        ('A7_C0871381', '7', 1, 'social cognition'),\n",
    "        ('A8_C2188220', '8', 1, 'unusual behavior'),\n",
    "        ('A9_C2736987', '9', 1, 'dependent on others'),\n",
    "        ('A10_C4062239', '10', 1, 'difficulty comprehending communication'),\n",
    "        ('A11_C0036597', '11', 1, 'self-esteem'),\n",
    "        ('A11_C2945580', '11', 0, 'poor self-esteem (finding)'),\n",
    "        ('A12_C0566180', '12', 1, 'ability to convey feelings'),\n",
    "        ('A13_C0566087', '13', 1, 'difficulty taking turns in conversation'),\n",
    "        ('A13_C4064030', '13', 0, 'peer interactions are directed by self'),\n",
    "        ('A14_C0558189', '14', 1, 'abnormal movements'),\n",
    "        ('A15_C2018050', '15', 1, 'speech nonverbal communication skills facial expressions'),\n",
    "        ('A15_C2009191', '15', 0, 'facial expression is lacking for any social interchange'),\n",
    "        ('A16_C0870532', '16', 1, 'avoided eye contact'),\n",
    "        ('A17_C0037427', '17', 1, 'awareness of social cues'),\n",
    "        ('A17_C4064022', '17', 0, 'marked social disinhibition appears unaware of social cues and social requirements'),\n",
    "        ('A18_C0679458', '18', 1, 'poor self-esteem (finding)'),\n",
    "        ('A18_C0517164', '18', 0, 'develops close friendships'),\n",
    "        ('A19_C0566183', '19', 1, 'difficulty communicating thoughts'),\n",
    "        ('A20_C0543488', '20', 1, 'unusual sensory interests'),\n",
    "        ('A21_C0855217', '21', 1, 'spontaneous imitation of actions'),\n",
    "        ('A22_C3476168', '22', 1, 'prefers to play with other children'),\n",
    "        ('A23_C0548554', '23', 1, 'seeks no play that involves participation in groups of other children'),\n",
    "        ('A24_C1718229', '24', 0, 'prefers change in daily routine'),\n",
    "        ('A25_C1971332', '25', 1, 'very focused and intense on single objects to the point of tuning everyone out'),\n",
    "        ('A26_C0150521', '26', 1, 'offering comfort'),\n",
    "        ('A26_C1948140', '26', 0, 'never offers comfort to others'),\n",
    "        ('A27_C0037420', '27', 1, 'not initiate social interactions'),\n",
    "        ('A28_C0038271', '28', 1, 'repetitive stereotypical behavior'),\n",
    "        ('A29_C2317765', '29', 1, 'child always different'),\n",
    "        ('A30_C0679475', '30', 1, 'emotional outbursts'),\n",
    "        ('A31_C0679047', '31', 1, 'perseverative thoughts'),\n",
    "        ('A32_C0018581', '32', 1, 'handwashing'),\n",
    "        ('A33_C0233844', '33', 1, 'social awkwardness'),\n",
    "        ('A34_C0679463', '34', 1, 'indifference to feelings of others'),\n",
    "        ('A35_C0562450', '35', 1, 'difficult to engage in spontaneous conversation'),\n",
    "        ('A36_C4064030', '36', 1, 'not attending to social approaches from adults'),\n",
    "        ('A37_C1845337', '37', 1, 'lack of peer relationships'),\n",
    "        ('A38_C0221736', '38', 1, 'emotional reactions'),\n",
    "        ('A39_C0543488', '39', 1, 'restricted range of interests'),\n",
    "        ('A40_C1822065', '40', 1, 'engages in much imaginative play'),\n",
    "        ('A41_C0871597', '41', 1, 'wandering behavior'),\n",
    "        ('A42_C0234215', '42', 1, 'sensory discomfort'),\n",
    "        ('A43_C0474417', '43', 1, 'self-care behaviour'),\n",
    "        ('A44_C0474413', '44', 1, 'not spontaneously engaging in other children'),\n",
    "        ('A45_C1619754', '45', 1, 'usually looks up and pays attention when spoken to'),\n",
    "        ('A45_C4064666', '45', 0, 'rare or no social approaches of showing and directing attention'),\n",
    "        ('A46_C0015457', '46', 1, 'inappropriate facial expressions'),\n",
    "        ('A47_C2048502', '47', 1, 'inappropriate laughing, joking, or punning'),\n",
    "        ('A48_C4274577', '48', 1, 'able to understand humour'),\n",
    "        ('A49_C1971332', '49', 1, 'very focused and intense on single activities to the point of tuning everyone out'),\n",
    "        ('A50_C0562460', '50', 1, 'stereotypic movements repetitive hand flapping'),\n",
    "        ('A51_C4036182', '51', 1, 'difficulty answering questions'),\n",
    "        ('A52_C4019167', '52', 0, 'disorders, speech sound'),\n",
    "        ('A53_C2018113', '53', 1, 'speech tone'),\n",
    "        ('A54_C2182632', '54', 1, 'uses people as objects'),\n",
    "        ('A55_C0584950', '55', 1, 'spatial awareness'),\n",
    "        ('A55_C0424300', '55', 0, 'invades others personal space'),\n",
    "        ('A56_C0037420', '56', 1, 'unusual social interaction'),\n",
    "        ('A57_C3476168', '57', 1, 'does not usually play with other children'),\n",
    "        ('A58_C0589098', '58', 1, 'limited attention and focus'),\n",
    "        ('A58_C0235198', '58', 0, 'ability to convey appropriate level of detail'),\n",
    "        ('A59_C0205258', '59', 1, 'suspicious of others'),\n",
    "        ('A60_C0085632', '60', 1, 'little or no emotions indication facial expression range'),\n",
    "        ('A61_C0025362', '61', 0, 'mental flexibility'),\n",
    "        ('A62_C0235129', '62', 1, 'strange or illogical ideas'),\n",
    "        ('A63_C0037420', '63', 1, 'unusual social interaction'),\n",
    "        ('A64_C4061788', '64', 1, 'discomfort in social situations'),\n",
    "        ('A65_C0427180', '65', 1, 'starring blankly into space')\n",
    "    ]\n",
    "    \n",
    "    # Apply each condition to add new mapped term columns\n",
    "    for new_column, condition_column, condition, text in term_conditions:\n",
    "        df = add_column_based_on_condition2(df, new_column, condition_column, condition, text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combined_column(df, start_col=67, end_col=142, combined_column_name='combined'):\n",
    "    \"\"\"\n",
    "    Combines multiple columns into a single column with comma-separated values.\n",
    "    \"\"\"\n",
    "    df[combined_column_name] = df.iloc[:, start_col:end_col].apply(lambda x: \" ,\".join(x.astype(str)), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Step 3: Map ASD terms based on conditions\n",
    "SRS_df2 = map_asd_terms(SRS_df2)\n",
    "\n",
    "    # Step 4: Generate a combined column for summary\n",
    "SRS_df2 = generate_combined_column(SRS_df2, start_col=67, end_col=142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# combined_info = pd.read_csv('/home/skbae/Documents/skbae/ASD/PJT_Data/Questions/Pg_Final/Text_MACHT_SCQ/Step2 Mapping/patient_combined_info_1004_Oct23.csv')\n",
    "SRS_df2 = pd.read_csv('./SRS_data_total_20250102_all_mapped_F.csv')\n",
    "SRS_df2.columns #1023042441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCQ_MACHt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# combined_info = pd.read_csv('/home/skbae/Documents/skbae/ASD/PJT_Data/Questions/Pg_Final/Text_MACHT_SCQ/Step2 Mapping/patient_combined_info_1004_Oct23.csv')\n",
    "combined_info = pd.read_csv('./patient_combined_info_20250102.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_info_f =combined_info [['Subject_Id', 'Gender', 'Class/ASD', 'Family_History','1st_Screening_ASD_Criteria', 'Premature_Infant', 'Lanuage_Delay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_info_f =combined_info [['Subject_Id', 'Gender', 'Class/ASD', 'Family_History','1st_Screening_ASD_Criteria', 'Premature_Infant', 'Lanuage_Delay']]\n",
    "# combined_info_f.\n",
    "\n",
    "# 'combined_info_f' 데이터프레임에서 'Class/ASD' 열이 'ASD high'이고 'Family_History'가 1이거나 'Premature_Infant'인 행을 선택합니다.\n",
    "selected_data = combined_info_f[\n",
    "    (combined_info_f['Class/ASD'] == 'ASD_HIGH') & \n",
    "    ((combined_info_f['Family_History'] == 1) | (combined_info_f['Premature_Infant'] == 1)) &\n",
    "    (combined_info_f['1st_Screening_ASD_Criteria'] == 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'selected_data' 데이터프레임에서 'Subject_Id' 열을 선택합니다.\n",
    "excluded_subject_ids = selected_data['Subject_Id']\n",
    "\n",
    "# 선택된 'Subject_Id'를 출력합니다. : need to exclude the model building \n",
    "print(excluded_subject_ids.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SCQ :T_ASD_SCQ.to_csv('./SCQ_data_total_20050102_all_mapped_f.csv', header=True, index=False) # 1004\n",
    "import pandas as pd\n",
    "df_SCQ_ASD = pd.read_csv('./SCQ_data_total_20050102_all_mapped_f.csv', dtype={'subject_id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scq=df_SCQ_ASD[['SubjectId', 'class','combined']]\n",
    "df_scq.columns =['SubjectId','Class','Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MCHAT data\n",
    "import pandas as pd\n",
    "# #1004\n",
    "# T_ASD.to_csv('./MCHAT_data_total_1004_oct23f_nov01.csv', header=True, index=False)\n",
    "\n",
    "# T_ASD_new= pd.read_csv('./MCHAT_data_total_1004_oct23f_nov01.csv')\n",
    "T_ASD_new= pd.read_csv('./MCHAT_data_total_20250102_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=T_ASD_new[['SubjectId','Class','combined']]\n",
    "df.columns =['SubjectId','Class','Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns =['SubjectId','M_Class','MCHAT_Text']\n",
    "df_scq.columns =['SubjectId','SCQ_Class','SCQ_Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23138/3895105764.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['SubjectId'] = df['SubjectId'].astype(str)\n",
      "/tmp/ipykernel_23138/3895105764.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_scq['SubjectId'] = df_scq['SubjectId'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "df['SubjectId'] = df['SubjectId'].astype(str)\n",
    "df_scq['SubjectId'] = df_scq['SubjectId'].astype(str)\n",
    "\n",
    "# Now, you can merge the dataframes\n",
    "merged_df = df_scq.merge(df, on='SubjectId', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['M_Class'] = merged_df['M_Class'].replace({ 1: 'TD', 2: 'High', 3: 'ASD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'SCQ_Text' and 'MCHAT_Text' with '[SEP]' token\n",
    "merged_df['Combined_Text'] = merged_df.apply(lambda row: f\"{row['SCQ_Text']} [SEP] {row['MCHAT_Text']}\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Roberta :RoBERTa는 두 문장을 연결할 때 문장 사이에 특별한 토큰 없이 공백만 사용\n",
    "merged_df['Combined_Text2'] = merged_df.apply(lambda row: f\"{row['SCQ_Text']} {row['MCHAT_Text']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove commas from 'Combined_Text'\n",
    "merged_df['Combined_Text'] = merged_df['Combined_Text'].str.replace(\",\", \"\")\n",
    "# # Remove commas from 'Combined_Text'\n",
    "merged_df['Combined_Text2'] = merged_df['Combined_Text2'].str.replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df.to_csv('./merged_df_SCQ_MCHAT_20250102_0106.csv', index=False)\n",
    "# merged_df를 JSON 파일로 내보내기\n",
    "merged_df.to_json('./merged_df_SCQ_MCHAT_20250102_0106.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert exclude_subject_ids to string\n",
    "excluded_subject_ids  = [str(id) for id in excluded_subject_ids ]\n",
    "\n",
    "# # Exclude certain subject IDs\n",
    "# df_scq_F = df_scq[~df_scq['SubjectId'].isin(excluded_subject_ids )]\n",
    "\n",
    "\n",
    "# Convert 'SubjectId' to string\n",
    "merged_df['SubjectId'] = merged_df['SubjectId'].astype(str)\n",
    "\n",
    "merged_df_F = merged_df[~merged_df['SubjectId'].isin(excluded_subject_ids)]\n",
    "\n",
    "df_o=merged_df_F \n",
    "# for SCQ_l\n",
    "# df_o=df_scq_F\n",
    "df_o.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'New_Class' using 'SCQ_Class', but fill NA values with 'M_Class'\n",
    "df_o['New_Class'] = df_o['SCQ_Class'].fillna(df_o['M_Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o['New_Class'] = df_o['New_Class'].replace({'td': 'TD', 'high': 'High', 'asd': 'ASD'})\n",
    "df_o['New_Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCHA and SCQ_l merged\n",
    "df_sF= df_o [['SubjectId',  'New_Class', 'Combined_Text2']]\n",
    "df_sF.columns=['SubjectId','Class','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    # torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "random_seed = 42\n",
    "set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_mapping4 = {\n",
    "    'High': 1, # High risk of ASD\n",
    "    'ASD': 1, # ASD\n",
    "    'TD': 0, # ASD\n",
    "}\n",
    "\n",
    "# Select only rows with 'High' and 'ASD'\n",
    "df_sF4 = df_sF\n",
    "\n",
    "df_sF4['label'] = df_sF4['Class'].replace(ASD_mapping4)\n",
    "print(df_sF4.label.value_counts())\n",
    "df_m4=df_sF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1032\n",
      "Validation set size: 129\n",
      "Test set size: 129\n",
      "\n",
      "Label distribution in Train set:\n",
      "label\n",
      "1    0.665698\n",
      "0    0.334302\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Label distribution in Validation set:\n",
      "label\n",
      "1    0.604651\n",
      "0    0.395349\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Label distribution in Test set:\n",
      "label\n",
      "1    0.627907\n",
      "0    0.372093\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# # 레이블 설정\n",
    "# df_sF4['label'] = df_sF4['Class'].replace(ASD_mapping4)\n",
    "# print(df_sF4.label.value_counts())\n",
    "# df_m4 = df_sF4\n",
    "\n",
    "# Initialize StratifiedGroupKFold for train and temp (validation + test)\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Get the indices for training and temp sets\n",
    "for train_idx, temp_idx in sgkf.split(df_m4, df_m4['label'], groups=df_m4['SubjectId']):\n",
    "    break\n",
    "\n",
    "# Create the training and temp sets\n",
    "train = df_m4.iloc[train_idx]\n",
    "temp = df_m4.iloc[temp_idx]\n",
    "\n",
    "# Initialize StratifiedGroupKFold for validation and test\n",
    "sgkf = StratifiedGroupKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# Get the indices for validation and test sets\n",
    "for val_idx, test_idx in sgkf.split(temp, temp['label'], groups=temp['SubjectId']):\n",
    "    break\n",
    "\n",
    "# Create the validation and test sets\n",
    "val = temp.iloc[val_idx]\n",
    "test = temp.iloc[test_idx]\n",
    "\n",
    "# Print the sizes of the datasets to verify the split\n",
    "print(f\"Train set size: {len(train)}\")\n",
    "print(f\"Validation set size: {len(val)}\")\n",
    "print(f\"Test set size: {len(test)}\")\n",
    "\n",
    "# Verify the label distribution\n",
    "print(\"\\nLabel distribution in Train set:\")\n",
    "print(train['label'].value_counts(normalize=True))\n",
    "print(\"\\nLabel distribution in Validation set:\")\n",
    "print(val['label'].value_counts(normalize=True))\n",
    "print(\"\\nLabel distribution in Test set:\")\n",
    "print(test['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    687\n",
      "0    345\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    78\n",
      "0    51\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    81\n",
      "0    48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# after the chekin g the other lab part 2 below \n",
    "print(train['label'].value_counts())\n",
    "print(val['label'].value_counts())\n",
    "print(test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m4.to_json('./df_m4_SCQ_MCAHT_20250102_labelsplit_0106F.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.to_json('./train_SCQ_MCAHT_20250102_labelsplit_0106.json', orient='records', lines=True)\n",
    "val.to_json('./val_SCQ_MCAHT_20250102_labelsplit_0106.json', orient='records', lines=True)\n",
    "test.to_json('./test_SCQ_MCAHT_20250102_labelsplit_0106.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
